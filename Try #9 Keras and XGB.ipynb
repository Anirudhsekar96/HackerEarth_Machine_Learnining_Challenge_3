{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('DATASET/train.csv')\n",
    "test = pd.read_csv('DATASET/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data has 12137810 rows and 10 columns\n",
      "The test data has 3706907 rows and 9 columns\n"
     ]
    }
   ],
   "source": [
    "print ('The train data has {} rows and {} columns'.format(train.shape[0],train.shape[1]))\n",
    "print ('The test data has {} rows and {} columns'.format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>datetime</th>\n",
       "      <th>siteid</th>\n",
       "      <th>offerid</th>\n",
       "      <th>category</th>\n",
       "      <th>merchant</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>browserid</th>\n",
       "      <th>devid</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDsrk7SoW</td>\n",
       "      <td>2017-01-14 09:42:09</td>\n",
       "      <td>4709696.0</td>\n",
       "      <td>887235</td>\n",
       "      <td>17714</td>\n",
       "      <td>20301556</td>\n",
       "      <td>e</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDmMSxHur</td>\n",
       "      <td>2017-01-18 17:50:53</td>\n",
       "      <td>5189467.0</td>\n",
       "      <td>178235</td>\n",
       "      <td>21407</td>\n",
       "      <td>9434818</td>\n",
       "      <td>b</td>\n",
       "      <td>Mozilla Firefox</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDVLNN0Ut</td>\n",
       "      <td>2017-01-11 12:46:49</td>\n",
       "      <td>98480.0</td>\n",
       "      <td>518539</td>\n",
       "      <td>25085</td>\n",
       "      <td>2050923</td>\n",
       "      <td>a</td>\n",
       "      <td>Edge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID32T6wwQ</td>\n",
       "      <td>2017-01-17 10:18:43</td>\n",
       "      <td>8896401.0</td>\n",
       "      <td>390352</td>\n",
       "      <td>40339</td>\n",
       "      <td>72089744</td>\n",
       "      <td>c</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDqUShzMg</td>\n",
       "      <td>2017-01-14 16:02:33</td>\n",
       "      <td>5635120.0</td>\n",
       "      <td>472937</td>\n",
       "      <td>12052</td>\n",
       "      <td>39507200</td>\n",
       "      <td>d</td>\n",
       "      <td>Mozilla Firefox</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID             datetime     siteid  offerid  category  merchant  \\\n",
       "0  IDsrk7SoW  2017-01-14 09:42:09  4709696.0   887235     17714  20301556   \n",
       "1  IDmMSxHur  2017-01-18 17:50:53  5189467.0   178235     21407   9434818   \n",
       "2  IDVLNN0Ut  2017-01-11 12:46:49    98480.0   518539     25085   2050923   \n",
       "3  ID32T6wwQ  2017-01-17 10:18:43  8896401.0   390352     40339  72089744   \n",
       "4  IDqUShzMg  2017-01-14 16:02:33  5635120.0   472937     12052  39507200   \n",
       "\n",
       "  countrycode        browserid    devid  click  \n",
       "0           e          Firefox      NaN      0  \n",
       "1           b  Mozilla Firefox  Desktop      0  \n",
       "2           a             Edge      NaN      0  \n",
       "3           c          Firefox   Mobile      0  \n",
       "4           d  Mozilla Firefox  Desktop      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imputing missing values\n",
    "train['siteid'].fillna(-999, inplace=True)\n",
    "test['siteid'].fillna(-999, inplace=True)\n",
    "\n",
    "train['browserid'].fillna(\"None\",inplace=True)\n",
    "test['browserid'].fillna(\"None\", inplace=True)\n",
    "\n",
    "train['devid'].fillna(\"None\",inplace=True)\n",
    "test['devid'].fillna(\"None\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create timebased features\n",
    "\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "train['tweekday'] = train['datetime'].dt.weekday\n",
    "test['tweekday'] = test['datetime'].dt.weekday\n",
    "\n",
    "train['tmonth'] = train['datetime'].dt.month\n",
    "test['tmonth'] = test['datetime'].dt.month\n",
    "\n",
    "train['tday'] = train['datetime'].dt.day\n",
    "test['tday'] = test['datetime'].dt.day\n",
    "\n",
    "train['tyear'] = train['datetime'].dt.year\n",
    "test['tyear'] = test['datetime'].dt.year\n",
    "\n",
    "train['thour'] = train['datetime'].dt.hour\n",
    "test['thour'] = test['datetime'].dt.hour\n",
    "\n",
    "train['tminute'] = train['datetime'].dt.minute\n",
    "test['tminute'] = test['datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create aggregate features\n",
    "site_offer_count = train.groupby(['siteid','offerid']).size().reset_index()\n",
    "site_offer_count.columns = ['siteid','offerid','site_offer_count']\n",
    "\n",
    "site_offer_count_test = test.groupby(['siteid','offerid']).size().reset_index()\n",
    "site_offer_count_test.columns = ['siteid','offerid','site_offer_count']\n",
    "\n",
    "site_cat_count = train.groupby(['siteid','category']).size().reset_index()\n",
    "site_cat_count.columns = ['siteid','category','site_cat_count']\n",
    "\n",
    "site_cat_count_test = test.groupby(['siteid','category']).size().reset_index()\n",
    "site_cat_count_test.columns = ['siteid','category','site_cat_count']\n",
    "\n",
    "site_mcht_count = train.groupby(['siteid','merchant']).size().reset_index()\n",
    "site_mcht_count.columns = ['siteid','merchant','site_mcht_count']\n",
    "\n",
    "site_mcht_count_test = test.groupby(['siteid','merchant']).size().reset_index()\n",
    "site_mcht_count_test.columns = ['siteid','merchant','site_mcht_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# joining all files\n",
    "agg_df = [site_offer_count,site_cat_count,site_mcht_count]\n",
    "agg_df_test = [site_offer_count_test,site_cat_count_test,site_mcht_count_test]\n",
    "\n",
    "for x in agg_df:\n",
    "    train = train.merge(x)\n",
    "    \n",
    "for x in agg_df_test:\n",
    "    test = test.merge(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for c in list(train.select_dtypes(include=['object']).columns):\n",
    "    if c != 'ID':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12137810, 19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sample 10% data - to avoid memory troubles\n",
    "# if you have access to large machines, you can use more data for training\n",
    "\n",
    "train = train.sample(train.shape[0])\n",
    "print (train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select columns to choose\n",
    "cols_to_use = [x for x in train.columns if x not in list(['ID','datetime','click'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# standarise data before training\n",
    "scaler = StandardScaler().fit(train[cols_to_use])\n",
    "\n",
    "strain = scaler.transform(train[cols_to_use])\n",
    "stest = scaler.transform(test[cols_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validation split\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(strain, train.click, test_size = 0.1, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10924029, 16)\n",
      "(1213781, 16)\n",
      "(10924029,)\n",
      "(1213781,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_valid.shape)\n",
    "print (Y_train.shape)\n",
    "print (Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model architechture\n",
    "def keras_model(train):\n",
    "    \n",
    "    input_dim = train.shape[1]\n",
    "    classes = 2\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation = 'relu', input_shape = (input_dim,)))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dense(classes, activation = 'sigmoid'))\n",
    "    model.compile(optimizer = 'adam', loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "callback = EarlyStopping(monitor='val_acc',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot target columns\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_valid = to_categorical(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10924029 samples, validate on 1213781 samples\n",
      "Epoch 1/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0673 - acc: 0.9772 - val_loss: 0.0620 - val_acc: 0.9785\n",
      "Epoch 2/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0594 - acc: 0.9797 - val_loss: 0.0577 - val_acc: 0.9803\n",
      "Epoch 3/50\n",
      "10924029/10924029 [==============================] - 37s - loss: 0.0564 - acc: 0.9807 - val_loss: 0.0552 - val_acc: 0.9810\n",
      "Epoch 4/50\n",
      "10924029/10924029 [==============================] - 37s - loss: 0.0548 - acc: 0.9812 - val_loss: 0.0550 - val_acc: 0.9811\n",
      "Epoch 5/50\n",
      "10924029/10924029 [==============================] - 37s - loss: 0.0538 - acc: 0.9815 - val_loss: 0.0574 - val_acc: 0.9804\n",
      "Epoch 6/50\n",
      "10924029/10924029 [==============================] - 37s - loss: 0.0533 - acc: 0.9817 - val_loss: 0.0535 - val_acc: 0.9818\n",
      "Epoch 7/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0526 - acc: 0.9819 - val_loss: 0.0553 - val_acc: 0.9812\n",
      "Epoch 8/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0522 - acc: 0.9820 - val_loss: 0.0559 - val_acc: 0.9808\n",
      "Epoch 9/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0518 - acc: 0.9821 - val_loss: 0.0588 - val_acc: 0.9799\n",
      "Epoch 10/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0517 - acc: 0.9822 - val_loss: 0.0531 - val_acc: 0.9819\n",
      "Epoch 11/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0512 - acc: 0.9823 - val_loss: 0.0526 - val_acc: 0.9818\n",
      "Epoch 12/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0509 - acc: 0.9825 - val_loss: 0.0505 - val_acc: 0.9825\n",
      "Epoch 13/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0507 - acc: 0.9825 - val_loss: 0.0513 - val_acc: 0.9825\n",
      "Epoch 14/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0504 - acc: 0.9826 - val_loss: 0.0503 - val_acc: 0.9827\n",
      "Epoch 15/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0503 - acc: 0.9826 - val_loss: 0.0550 - val_acc: 0.9810\n",
      "Epoch 16/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0501 - acc: 0.9827 - val_loss: 0.0504 - val_acc: 0.9828\n",
      "Epoch 17/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0498 - acc: 0.9828 - val_loss: 0.0504 - val_acc: 0.9827\n",
      "Epoch 18/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0497 - acc: 0.9828 - val_loss: 0.0497 - val_acc: 0.9829\n",
      "Epoch 19/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0497 - acc: 0.9829 - val_loss: 0.0502 - val_acc: 0.9828\n",
      "Epoch 20/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0494 - acc: 0.9829 - val_loss: 0.0503 - val_acc: 0.9827\n",
      "Epoch 21/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0492 - acc: 0.9830 - val_loss: 0.0506 - val_acc: 0.9826\n",
      "Epoch 22/50\n",
      "10924029/10924029 [==============================] - 38s - loss: 0.0490 - acc: 0.9831 - val_loss: 0.0511 - val_acc: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd5004af490>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model = keras_model(X_train)\n",
    "model.fit(X_train, Y_train, 2000, 50, callbacks=[callback],validation_data=(X_valid, Y_valid),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1211808/1213781 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98102068719767144"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check validation accuracy\n",
    "vpreds = model.predict_proba(X_valid)[:,1]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true = Y_valid[:,1], y_score=vpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3706432/3706907 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# predict on test data\n",
    "test_preds = model.predict_proba(stest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create submission file\n",
    "submit = pd.DataFrame({'ID':test.ID, 'click':test_preds})\n",
    "submit.to_csv('Submission/Keras_subNN1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_XGB = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y__pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
