{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('DATASET/train.csv')\n",
    "test = pd.read_csv('DATASET/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data has 12137810 rows and 10 columns\n",
      "The test data has 3706907 rows and 9 columns\n"
     ]
    }
   ],
   "source": [
    "print ('The train data has {} rows and {} columns'.format(train.shape[0],train.shape[1]))\n",
    "print ('The test data has {} rows and {} columns'.format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>datetime</th>\n",
       "      <th>siteid</th>\n",
       "      <th>offerid</th>\n",
       "      <th>category</th>\n",
       "      <th>merchant</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>browserid</th>\n",
       "      <th>devid</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDsrk7SoW</td>\n",
       "      <td>2017-01-14 09:42:09</td>\n",
       "      <td>4709696.0</td>\n",
       "      <td>887235</td>\n",
       "      <td>17714</td>\n",
       "      <td>20301556</td>\n",
       "      <td>e</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDmMSxHur</td>\n",
       "      <td>2017-01-18 17:50:53</td>\n",
       "      <td>5189467.0</td>\n",
       "      <td>178235</td>\n",
       "      <td>21407</td>\n",
       "      <td>9434818</td>\n",
       "      <td>b</td>\n",
       "      <td>Mozilla Firefox</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDVLNN0Ut</td>\n",
       "      <td>2017-01-11 12:46:49</td>\n",
       "      <td>98480.0</td>\n",
       "      <td>518539</td>\n",
       "      <td>25085</td>\n",
       "      <td>2050923</td>\n",
       "      <td>a</td>\n",
       "      <td>Edge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID32T6wwQ</td>\n",
       "      <td>2017-01-17 10:18:43</td>\n",
       "      <td>8896401.0</td>\n",
       "      <td>390352</td>\n",
       "      <td>40339</td>\n",
       "      <td>72089744</td>\n",
       "      <td>c</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDqUShzMg</td>\n",
       "      <td>2017-01-14 16:02:33</td>\n",
       "      <td>5635120.0</td>\n",
       "      <td>472937</td>\n",
       "      <td>12052</td>\n",
       "      <td>39507200</td>\n",
       "      <td>d</td>\n",
       "      <td>Mozilla Firefox</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID             datetime     siteid  offerid  category  merchant  \\\n",
       "0  IDsrk7SoW  2017-01-14 09:42:09  4709696.0   887235     17714  20301556   \n",
       "1  IDmMSxHur  2017-01-18 17:50:53  5189467.0   178235     21407   9434818   \n",
       "2  IDVLNN0Ut  2017-01-11 12:46:49    98480.0   518539     25085   2050923   \n",
       "3  ID32T6wwQ  2017-01-17 10:18:43  8896401.0   390352     40339  72089744   \n",
       "4  IDqUShzMg  2017-01-14 16:02:33  5635120.0   472937     12052  39507200   \n",
       "\n",
       "  countrycode        browserid    devid  click  \n",
       "0           e          Firefox      NaN      0  \n",
       "1           b  Mozilla Firefox  Desktop      0  \n",
       "2           a             Edge      NaN      0  \n",
       "3           c          Firefox   Mobile      0  \n",
       "4           d  Mozilla Firefox  Desktop      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imputing missing values\n",
    "train['siteid'].fillna(-999, inplace=True)\n",
    "test['siteid'].fillna(-999, inplace=True)\n",
    "\n",
    "train['browserid'].fillna(\"None\",inplace=True)\n",
    "test['browserid'].fillna(\"None\", inplace=True)\n",
    "\n",
    "train['devid'].fillna(\"None\",inplace=True)\n",
    "test['devid'].fillna(\"None\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create timebased features\n",
    "\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "train['tweekday'] = train['datetime'].dt.weekday\n",
    "test['tweekday'] = test['datetime'].dt.weekday\n",
    "\n",
    "train['tyear'] = train['datetime'].dt.year\n",
    "test['tyear'] = test['datetime'].dt.year\n",
    "\n",
    "train['month'] = train['datetime'].dt.month\n",
    "test['month'] = test['datetime'].dt.month\n",
    "\n",
    "train['tday'] = train['datetime'].dt.day\n",
    "test['tday'] = test['datetime'].dt.day\n",
    "\n",
    "train['thour'] = train['datetime'].dt.hour\n",
    "test['thour'] = test['datetime'].dt.hour\n",
    "\n",
    "train['tminute'] = train['datetime'].dt.minute\n",
    "test['tminute'] = test['datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create aggregate features\n",
    "site_offer_count = train.groupby(['siteid','offerid']).size().reset_index()\n",
    "site_offer_count.columns = ['siteid','offerid','site_offer_count']\n",
    "\n",
    "site_offer_count_test = test.groupby(['siteid','offerid']).size().reset_index()\n",
    "site_offer_count_test.columns = ['siteid','offerid','site_offer_count']\n",
    "\n",
    "site_cat_count = train.groupby(['siteid','category']).size().reset_index()\n",
    "site_cat_count.columns = ['siteid','category','site_cat_count']\n",
    "\n",
    "site_cat_count_test = test.groupby(['siteid','category']).size().reset_index()\n",
    "site_cat_count_test.columns = ['siteid','category','site_cat_count']\n",
    "\n",
    "site_mcht_count = train.groupby(['siteid','merchant']).size().reset_index()\n",
    "site_mcht_count.columns = ['siteid','merchant','site_mcht_count']\n",
    "\n",
    "site_mcht_count_test = test.groupby(['siteid','merchant']).size().reset_index()\n",
    "site_mcht_count_test.columns = ['siteid','merchant','site_mcht_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# joining all files\n",
    "agg_df = [site_offer_count,site_cat_count,site_mcht_count]\n",
    "agg_df_test = [site_offer_count_test,site_cat_count_test,site_mcht_count_test]\n",
    "\n",
    "for x in agg_df:\n",
    "    train = train.merge(x)\n",
    "    \n",
    "for x in agg_df_test:\n",
    "    test = test.merge(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for c in list(train.select_dtypes(include=['object']).columns):\n",
    "    if c != 'ID':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sample 10% data - to avoid memory troubles\n",
    "# if you have access to large machines, you can use more data for training\n",
    "\n",
    "train = train.sample(int(1e6))\n",
    "print (train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select columns to choose\n",
    "cols_to_use = [x for x in train.columns if x not in list(['ID','datetime','click'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# standarise data before training\n",
    "scaler = StandardScaler().fit(train[cols_to_use])\n",
    "\n",
    "strain = scaler.transform(train[cols_to_use])\n",
    "stest = scaler.transform(test[cols_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train validation split\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(strain, train.click, test_size = 0.1, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900000, 16)\n",
      "(100000, 16)\n",
      "(900000,)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_valid.shape)\n",
    "print (Y_train.shape)\n",
    "print (Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model architechture\n",
    "def keras_model(train):\n",
    "    \n",
    "    input_dim = train.shape[1]\n",
    "    classes = 2\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation = 'relu', input_shape = (input_dim,)))\n",
    "    model.add(Dense(30, activation = 'relu'))\n",
    "    model.add(Dense(classes, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam', loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "callback = EarlyStopping(monitor='val_acc',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot target columns\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_valid = to_categorical(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900000 samples, validate on 100000 samples\n",
      "Epoch 1/100\n",
      "900000/900000 [==============================] - 2s - loss: 0.1310 - acc: 0.9629 - val_loss: 0.0950 - val_acc: 0.9678\n",
      "Epoch 2/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0888 - acc: 0.9706 - val_loss: 0.0856 - val_acc: 0.9711\n",
      "Epoch 3/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0824 - acc: 0.9721 - val_loss: 0.0804 - val_acc: 0.9723\n",
      "Epoch 4/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0769 - acc: 0.9734 - val_loss: 0.0750 - val_acc: 0.9733\n",
      "Epoch 5/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0718 - acc: 0.9751 - val_loss: 0.0702 - val_acc: 0.9759\n",
      "Epoch 6/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0690 - acc: 0.9762 - val_loss: 0.0682 - val_acc: 0.9763\n",
      "Epoch 7/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0675 - acc: 0.9768 - val_loss: 0.0670 - val_acc: 0.9771\n",
      "Epoch 8/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0666 - acc: 0.9771 - val_loss: 0.0660 - val_acc: 0.9772\n",
      "Epoch 9/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0658 - acc: 0.9773 - val_loss: 0.0652 - val_acc: 0.9776\n",
      "Epoch 10/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0650 - acc: 0.9776 - val_loss: 0.0649 - val_acc: 0.9775\n",
      "Epoch 11/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0645 - acc: 0.9778 - val_loss: 0.0643 - val_acc: 0.9779\n",
      "Epoch 12/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0640 - acc: 0.9780 - val_loss: 0.0637 - val_acc: 0.9781\n",
      "Epoch 13/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0637 - acc: 0.9780 - val_loss: 0.0636 - val_acc: 0.9781\n",
      "Epoch 14/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0632 - acc: 0.9782 - val_loss: 0.0632 - val_acc: 0.9785\n",
      "Epoch 15/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0629 - acc: 0.9783 - val_loss: 0.0631 - val_acc: 0.9784\n",
      "Epoch 16/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0625 - acc: 0.9784 - val_loss: 0.0625 - val_acc: 0.9786\n",
      "Epoch 17/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0623 - acc: 0.9785 - val_loss: 0.0627 - val_acc: 0.9787\n",
      "Epoch 18/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0620 - acc: 0.9786 - val_loss: 0.0624 - val_acc: 0.9789\n",
      "Epoch 19/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0618 - acc: 0.9787 - val_loss: 0.0618 - val_acc: 0.9788\n",
      "Epoch 20/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0616 - acc: 0.9787 - val_loss: 0.0618 - val_acc: 0.9789\n",
      "Epoch 21/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0614 - acc: 0.9788 - val_loss: 0.0617 - val_acc: 0.9790\n",
      "Epoch 22/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0613 - acc: 0.9788 - val_loss: 0.0617 - val_acc: 0.9790\n",
      "Epoch 23/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0612 - acc: 0.9790 - val_loss: 0.0627 - val_acc: 0.9782\n",
      "Epoch 24/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0610 - acc: 0.9790 - val_loss: 0.0615 - val_acc: 0.9788\n",
      "Epoch 25/100\n",
      "900000/900000 [==============================] - 1s - loss: 0.0609 - acc: 0.9790 - val_loss: 0.0614 - val_acc: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6969f16510>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model = keras_model(X_train)\n",
    "model.fit(X_train, Y_train, 2000, 100, callbacks=[callback],validation_data=(X_valid, Y_valid),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99072/100000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97048909368891068"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check validation accuracy\n",
    "vpreds = model.predict_proba(X_valid)[:,1]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true = Y_valid[:,1], y_score=vpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3704544/3706907 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# predict on test data\n",
    "test_preds = model.predict_proba(stest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create submission file\n",
    "submit = pd.DataFrame({'ID':test.ID, 'click':test_preds})\n",
    "submit.to_csv('Submission/Keras_subNew3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGB_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model.fit(strain, train.click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds2 = XGB_model.predict_proba(stest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0033376857"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00046367833"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitXGB = pd.DataFrame({'ID':test.ID, 'click':test_preds2})\n",
    "submitXGB.to_csv('Submission/XGB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_ensemble = (test_preds2 + test_preds)/2.0\n",
    "submitE = pd.DataFrame({'ID':test.ID, 'click':test_pred_ensemble})\n",
    "submitE.to_csv('Submission/ENSEMBLE1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000, 16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpreds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_pred = model.predict(strain)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97155038329459154"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train.click,Y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 16)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_l1 = pd.DataFrame(data=strain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_l1[\"Y_pred\"]=Y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 17)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_l1 = pd.DataFrame(data=stest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_l1[\"Y_pred\"] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model_L2 = XGBClassifier()\n",
    "XGB_model_L2.fit(Data_l1, train.click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_L2 = XGB_model_L2.predict_proba(Test_l1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submitXGB_l2 = pd.DataFrame({'ID':test.ID, 'click':test_preds_L2})\n",
    "submitXGB_l2.to_csv('Submission/XGB_L2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
