{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('DATASET/train.csv')\n",
    "test = pd.read_csv('DATASET/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data has 12137810 rows and 10 columns\n",
      "The test data has 3706907 rows and 9 columns\n"
     ]
    }
   ],
   "source": [
    "print ('The train data has {} rows and {} columns'.format(train.shape[0],train.shape[1]))\n",
    "print ('The test data has {} rows and {} columns'.format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>datetime</th>\n",
       "      <th>siteid</th>\n",
       "      <th>offerid</th>\n",
       "      <th>category</th>\n",
       "      <th>merchant</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>browserid</th>\n",
       "      <th>devid</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDsrk7SoW</td>\n",
       "      <td>2017-01-14 09:42:09</td>\n",
       "      <td>4709696.0</td>\n",
       "      <td>887235</td>\n",
       "      <td>17714</td>\n",
       "      <td>20301556</td>\n",
       "      <td>e</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDmMSxHur</td>\n",
       "      <td>2017-01-18 17:50:53</td>\n",
       "      <td>5189467.0</td>\n",
       "      <td>178235</td>\n",
       "      <td>21407</td>\n",
       "      <td>9434818</td>\n",
       "      <td>b</td>\n",
       "      <td>Mozilla Firefox</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDVLNN0Ut</td>\n",
       "      <td>2017-01-11 12:46:49</td>\n",
       "      <td>98480.0</td>\n",
       "      <td>518539</td>\n",
       "      <td>25085</td>\n",
       "      <td>2050923</td>\n",
       "      <td>a</td>\n",
       "      <td>Edge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID32T6wwQ</td>\n",
       "      <td>2017-01-17 10:18:43</td>\n",
       "      <td>8896401.0</td>\n",
       "      <td>390352</td>\n",
       "      <td>40339</td>\n",
       "      <td>72089744</td>\n",
       "      <td>c</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDqUShzMg</td>\n",
       "      <td>2017-01-14 16:02:33</td>\n",
       "      <td>5635120.0</td>\n",
       "      <td>472937</td>\n",
       "      <td>12052</td>\n",
       "      <td>39507200</td>\n",
       "      <td>d</td>\n",
       "      <td>Mozilla Firefox</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID             datetime     siteid  offerid  category  merchant  \\\n",
       "0  IDsrk7SoW  2017-01-14 09:42:09  4709696.0   887235     17714  20301556   \n",
       "1  IDmMSxHur  2017-01-18 17:50:53  5189467.0   178235     21407   9434818   \n",
       "2  IDVLNN0Ut  2017-01-11 12:46:49    98480.0   518539     25085   2050923   \n",
       "3  ID32T6wwQ  2017-01-17 10:18:43  8896401.0   390352     40339  72089744   \n",
       "4  IDqUShzMg  2017-01-14 16:02:33  5635120.0   472937     12052  39507200   \n",
       "\n",
       "  countrycode        browserid    devid  click  \n",
       "0           e          Firefox      NaN      0  \n",
       "1           b  Mozilla Firefox  Desktop      0  \n",
       "2           a             Edge      NaN      0  \n",
       "3           c          Firefox   Mobile      0  \n",
       "4           d  Mozilla Firefox  Desktop      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imputing missing values\n",
    "train['siteid'].fillna(-1, inplace=True)\n",
    "test['siteid'].fillna(-1, inplace=True)\n",
    "\n",
    "train['browserid'].fillna(\"None\",inplace=True)\n",
    "test['browserid'].fillna(\"None\", inplace=True)\n",
    "\n",
    "train['devid'].fillna(\"None\",inplace=True)\n",
    "test['devid'].fillna(\"None\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create timebased features\n",
    "\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "train['tweekday'] = train['datetime'].dt.weekday\n",
    "test['tweekday'] = test['datetime'].dt.weekday\n",
    "\n",
    "train['tmonth'] = train['datetime'].dt.month\n",
    "test['tmonth'] = test['datetime'].dt.month\n",
    "\n",
    "train['tday'] = train['datetime'].dt.day\n",
    "test['tday'] = test['datetime'].dt.day\n",
    "\n",
    "train['tyear'] = train['datetime'].dt.year\n",
    "test['tyear'] = test['datetime'].dt.year\n",
    "\n",
    "train['thour'] = train['datetime'].dt.hour\n",
    "test['thour'] = test['datetime'].dt.hour\n",
    "\n",
    "train['tminute'] = train['datetime'].dt.minute\n",
    "test['tminute'] = test['datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create aggregate features\n",
    "site_offer_count = train.groupby(['siteid','offerid']).size().reset_index()\n",
    "site_offer_count.columns = ['siteid','offerid','site_offer_count']\n",
    "\n",
    "site_offer_count_test = test.groupby(['siteid','offerid']).size().reset_index()\n",
    "site_offer_count_test.columns = ['siteid','offerid','site_offer_count']\n",
    "\n",
    "site_cat_count = train.groupby(['siteid','category']).size().reset_index()\n",
    "site_cat_count.columns = ['siteid','category','site_cat_count']\n",
    "\n",
    "site_cat_count_test = test.groupby(['siteid','category']).size().reset_index()\n",
    "site_cat_count_test.columns = ['siteid','category','site_cat_count']\n",
    "\n",
    "site_mcht_count = train.groupby(['siteid','merchant']).size().reset_index()\n",
    "site_mcht_count.columns = ['siteid','merchant','site_mcht_count']\n",
    "\n",
    "site_mcht_count_test = test.groupby(['siteid','merchant']).size().reset_index()\n",
    "site_mcht_count_test.columns = ['siteid','merchant','site_mcht_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# joining all files\n",
    "agg_df = [site_offer_count,site_cat_count,site_mcht_count]\n",
    "agg_df_test = [site_offer_count_test,site_cat_count_test,site_mcht_count_test]\n",
    "\n",
    "for x in agg_df:\n",
    "    train = train.merge(x)\n",
    "    \n",
    "for x in agg_df_test:\n",
    "    test = test.merge(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for c in list(train.select_dtypes(include=['object']).columns):\n",
    "    if c != 'ID':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12137810, 19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sample 10% data - to avoid memory troubles\n",
    "# if you have access to large machines, you can use more data for training\n",
    "\n",
    "train = train.sample(train.shape[0])\n",
    "print (train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select columns to choose\n",
    "cols_to_use = [x for x in train.columns if x not in list(['ID','datetime','click'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2ad1b40a62c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# standarise data before training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_to_use\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_to_use\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    581\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    582\u001b[0m                         \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# standarise data before training\n",
    "scaler = StandardScaler().fit(train[cols_to_use])\n",
    "\n",
    "strain = scaler.transform(train[cols_to_use])\n",
    "stest = scaler.transform(test[cols_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train validation split\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(strain, train.click, test_size = 0.1, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (X_train.shape)\n",
    "print (X_valid.shape)\n",
    "print (Y_train.shape)\n",
    "print (Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model architechture\n",
    "def keras_model(train):\n",
    "    \n",
    "    input_dim = train.shape[1]\n",
    "    classes = 2\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation = 'relu', input_shape = (input_dim,)))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dense(classes, activation = 'sigmoid'))\n",
    "    model.compile(optimizer = 'adam', loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "callback = EarlyStopping(monitor='val_acc',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot target columns\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_valid = to_categorical(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "model = keras_model(X_train)\n",
    "model.fit(X_train, Y_train, 2000, 50, callbacks=[callback],validation_data=(X_valid, Y_valid),shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
