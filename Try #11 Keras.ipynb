{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('DATASET/train.csv')\n",
    "test = pd.read_csv('DATASET/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data has 12137810 rows and 10 columns\n",
      "The test data has 3706907 rows and 9 columns\n"
     ]
    }
   ],
   "source": [
    "print ('The train data has {} rows and {} columns'.format(train.shape[0],train.shape[1]))\n",
    "print ('The test data has {} rows and {} columns'.format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>datetime</th>\n",
       "      <th>siteid</th>\n",
       "      <th>offerid</th>\n",
       "      <th>category</th>\n",
       "      <th>merchant</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>browserid</th>\n",
       "      <th>devid</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDsrk7SoW</td>\n",
       "      <td>2017-01-14 09:42:09</td>\n",
       "      <td>4709696.0</td>\n",
       "      <td>887235</td>\n",
       "      <td>17714</td>\n",
       "      <td>20301556</td>\n",
       "      <td>e</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDmMSxHur</td>\n",
       "      <td>2017-01-18 17:50:53</td>\n",
       "      <td>5189467.0</td>\n",
       "      <td>178235</td>\n",
       "      <td>21407</td>\n",
       "      <td>9434818</td>\n",
       "      <td>b</td>\n",
       "      <td>Mozilla Firefox</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDVLNN0Ut</td>\n",
       "      <td>2017-01-11 12:46:49</td>\n",
       "      <td>98480.0</td>\n",
       "      <td>518539</td>\n",
       "      <td>25085</td>\n",
       "      <td>2050923</td>\n",
       "      <td>a</td>\n",
       "      <td>Edge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID32T6wwQ</td>\n",
       "      <td>2017-01-17 10:18:43</td>\n",
       "      <td>8896401.0</td>\n",
       "      <td>390352</td>\n",
       "      <td>40339</td>\n",
       "      <td>72089744</td>\n",
       "      <td>c</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDqUShzMg</td>\n",
       "      <td>2017-01-14 16:02:33</td>\n",
       "      <td>5635120.0</td>\n",
       "      <td>472937</td>\n",
       "      <td>12052</td>\n",
       "      <td>39507200</td>\n",
       "      <td>d</td>\n",
       "      <td>Mozilla Firefox</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID             datetime     siteid  offerid  category  merchant  \\\n",
       "0  IDsrk7SoW  2017-01-14 09:42:09  4709696.0   887235     17714  20301556   \n",
       "1  IDmMSxHur  2017-01-18 17:50:53  5189467.0   178235     21407   9434818   \n",
       "2  IDVLNN0Ut  2017-01-11 12:46:49    98480.0   518539     25085   2050923   \n",
       "3  ID32T6wwQ  2017-01-17 10:18:43  8896401.0   390352     40339  72089744   \n",
       "4  IDqUShzMg  2017-01-14 16:02:33  5635120.0   472937     12052  39507200   \n",
       "\n",
       "  countrycode        browserid    devid  click  \n",
       "0           e          Firefox      NaN      0  \n",
       "1           b  Mozilla Firefox  Desktop      0  \n",
       "2           a             Edge      NaN      0  \n",
       "3           c          Firefox   Mobile      0  \n",
       "4           d  Mozilla Firefox  Desktop      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imputing missing values\n",
    "train['siteid'].fillna(-999, inplace=True)\n",
    "test['siteid'].fillna(-999, inplace=True)\n",
    "\n",
    "train['browserid'].fillna(\"None\",inplace=True)\n",
    "test['browserid'].fillna(\"None\", inplace=True)\n",
    "\n",
    "train['devid'].fillna(\"None\",inplace=True)\n",
    "test['devid'].fillna(\"None\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create timebased features\n",
    "\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "train['tweekday'] = train['datetime'].dt.weekday\n",
    "test['tweekday'] = test['datetime'].dt.weekday\n",
    "\n",
    "train['thour'] = train['datetime'].dt.hour\n",
    "test['thour'] = test['datetime'].dt.hour\n",
    "\n",
    "train['tminute'] = train['datetime'].dt.minute\n",
    "test['tminute'] = test['datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create aggregate features\n",
    "site_offer_count = train.groupby(['siteid','offerid']).size().reset_index()\n",
    "site_offer_count.columns = ['siteid','offerid','site_offer_count']\n",
    "\n",
    "site_offer_count_test = test.groupby(['siteid','offerid']).size().reset_index()\n",
    "site_offer_count_test.columns = ['siteid','offerid','site_offer_count']\n",
    "\n",
    "site_cat_count = train.groupby(['siteid','category']).size().reset_index()\n",
    "site_cat_count.columns = ['siteid','category','site_cat_count']\n",
    "\n",
    "site_cat_count_test = test.groupby(['siteid','category']).size().reset_index()\n",
    "site_cat_count_test.columns = ['siteid','category','site_cat_count']\n",
    "\n",
    "site_mcht_count = train.groupby(['siteid','merchant']).size().reset_index()\n",
    "site_mcht_count.columns = ['siteid','merchant','site_mcht_count']\n",
    "\n",
    "site_mcht_count_test = test.groupby(['siteid','merchant']).size().reset_index()\n",
    "site_mcht_count_test.columns = ['siteid','merchant','site_mcht_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# joining all files\n",
    "agg_df = [site_offer_count,site_cat_count,site_mcht_count]\n",
    "agg_df_test = [site_offer_count_test,site_cat_count_test,site_mcht_count_test]\n",
    "\n",
    "for x in agg_df:\n",
    "    train = train.merge(x)\n",
    "    \n",
    "for x in agg_df_test:\n",
    "    test = test.merge(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for c in list(train.select_dtypes(include=['object']).columns):\n",
    "    if c != 'ID':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12137810, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sample 10% data - to avoid memory troubles\n",
    "# if you have access to large machines, you can use more data for training\n",
    "\n",
    "train = train.sample(train.shape[0])\n",
    "print (train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select columns to choose\n",
    "cols_to_use = [x for x in train.columns if x not in list(['ID','datetime','click'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# standarise data before training\n",
    "scaler = StandardScaler().fit(train[cols_to_use])\n",
    "\n",
    "strain = scaler.transform(train[cols_to_use])\n",
    "stest = scaler.transform(test[cols_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train validation split\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(strain, train.click, test_size = 0.1, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10924029, 13)\n",
      "(1213781, 13)\n",
      "(10924029,)\n",
      "(1213781,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_valid.shape)\n",
    "print (Y_train.shape)\n",
    "print (Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model architechture\n",
    "def keras_model(train):\n",
    "    \n",
    "    input_dim = train.shape[1]\n",
    "    classes = 2\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation = 'relu', input_shape = (input_dim,)))\n",
    "    model.add(Dense(30, activation = 'relu'))\n",
    "    model.add(Dense(classes, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam', loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "callback = EarlyStopping(monitor='val_acc',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot target columns\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_valid = to_categorical(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10924029 samples, validate on 1213781 samples\n",
      "Epoch 1/100\n",
      "10924029/10924029 [==============================] - 21s - loss: 0.0796 - acc: 0.9729 - val_loss: 0.0660 - val_acc: 0.9773\n",
      "Epoch 2/100\n",
      "10924029/10924029 [==============================] - 20s - loss: 0.0641 - acc: 0.9778 - val_loss: 0.0634 - val_acc: 0.9782\n",
      "Epoch 3/100\n",
      "10924029/10924029 [==============================] - 20s - loss: 0.0608 - acc: 0.9790 - val_loss: 0.0593 - val_acc: 0.9796\n",
      "Epoch 4/100\n",
      "10924029/10924029 [==============================] - 19s - loss: 0.0578 - acc: 0.9800 - val_loss: 0.0578 - val_acc: 0.9802\n",
      "Epoch 5/100\n",
      "10924029/10924029 [==============================] - 19s - loss: 0.0560 - acc: 0.9806 - val_loss: 0.0645 - val_acc: 0.9774\n",
      "Epoch 6/100\n",
      "10924029/10924029 [==============================] - 21s - loss: 0.0550 - acc: 0.9809 - val_loss: 0.0571 - val_acc: 0.9804\n",
      "Epoch 7/100\n",
      "10924029/10924029 [==============================] - 20s - loss: 0.0542 - acc: 0.9811 - val_loss: 0.0585 - val_acc: 0.9797\n",
      "Epoch 8/100\n",
      "10924029/10924029 [==============================] - 19s - loss: 0.0538 - acc: 0.9813 - val_loss: 0.0584 - val_acc: 0.9798\n",
      "Epoch 9/100\n",
      "10924029/10924029 [==============================] - 20s - loss: 0.0534 - acc: 0.9814 - val_loss: 0.0531 - val_acc: 0.9816\n",
      "Epoch 10/100\n",
      "10924029/10924029 [==============================] - 19s - loss: 0.0530 - acc: 0.9815 - val_loss: 0.0533 - val_acc: 0.9814\n",
      "Epoch 11/100\n",
      "10924029/10924029 [==============================] - 20s - loss: 0.0527 - acc: 0.9816 - val_loss: 0.0536 - val_acc: 0.9815\n",
      "Epoch 12/100\n",
      "10924029/10924029 [==============================] - 20s - loss: 0.0526 - acc: 0.9816 - val_loss: 0.0530 - val_acc: 0.9816\n",
      "Epoch 13/100\n",
      "10924029/10924029 [==============================] - 20s - loss: 0.0525 - acc: 0.9817 - val_loss: 0.0539 - val_acc: 0.9812\n",
      "Epoch 14/100\n",
      "10924029/10924029 [==============================] - 20s - loss: 0.0522 - acc: 0.9817 - val_loss: 0.0563 - val_acc: 0.9806\n",
      "Epoch 15/100\n",
      "10924029/10924029 [==============================] - 20s - loss: 0.0522 - acc: 0.9818 - val_loss: 0.0542 - val_acc: 0.9814\n",
      "Epoch 16/100\n",
      "10924029/10924029 [==============================] - 21s - loss: 0.0520 - acc: 0.9819 - val_loss: 0.0539 - val_acc: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40df09a590>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model = keras_model(X_train)\n",
    "model.fit(X_train, Y_train, 2000, 100, callbacks=[callback],validation_data=(X_valid, Y_valid),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1211200/1213781 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97845322183259542"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check validation accuracy\n",
    "vpreds = model.predict_proba(X_valid)[:,1]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true = Y_valid[:,1], y_score=vpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3704256/3706907 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# predict on test data\n",
    "test_preds = model.predict_proba(stest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create submission file\n",
    "submit = pd.DataFrame({'ID':test.ID, 'click':test_preds})\n",
    "submit.to_csv('Submission/Keras_subNew1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
